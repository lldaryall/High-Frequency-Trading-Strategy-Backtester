name: Performance Benchmark

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  benchmark:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y cmake build-essential python3-dev python3-setuptools
    
    - name: Cache C++ build artifacts
      uses: actions/cache@v4
      with:
        path: |
          flashback/market/_match_cpp.so
        key: ${{ runner.os }}-cpp-extension-${{ hashFiles('cpp/**', 'CMakeLists.txt') }}
        restore-keys: |
          ${{ runner.os }}-cpp-extension-
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pybind11
        pip install -e .
        pip install -e ".[dev]"
    
    - name: Clean C++ build directory
      run: |
        # Clean the entire build directory to avoid path conflicts
        rm -rf cpp/build/
        # Ensure the build directory exists
        mkdir -p cpp/build
    
    - name: Build C++ extension
      run: make cpp
    
    - name: Test C++ extension
      run: make cpp-test
    
    - name: Run bit-for-bit reproducibility test
      run: |
        python -m pytest tests/unit/test_cpp_bit_for_bit.py -v
    
    - name: Run performance benchmarks
      run: make ci-bench
    
    - name: Calculate median speedup
      id: speedup
      run: |
        # Extract speedup from the largest benchmark CSV
        if [ -f "ci_benchmark_results/bench_1000000.csv" ]; then
          CSV_FILE="ci_benchmark_results/bench_1000000.csv"
        elif [ -f "ci_benchmark_results/bench_500000.csv" ]; then
          CSV_FILE="ci_benchmark_results/bench_500000.csv"
        else
          CSV_FILE="ci_benchmark_results/bench_100000.csv"
        fi
        
        # Check if CSV file exists and has data
        if [ ! -f "$CSV_FILE" ] || [ ! -s "$CSV_FILE" ]; then
          echo "Error: Benchmark CSV file not found or empty: $CSV_FILE"
          echo "Available files:"
          ls -la ci_benchmark_results/ || echo "No ci_benchmark_results directory found"
          exit 1
        fi
        
        # Calculate speedup from CSV
        PYTHON_OPS=$(tail -n +2 "$CSV_FILE" | head -n 1 | cut -d',' -f7)
        CPP_OPS=$(tail -n +2 "$CSV_FILE" | tail -n 1 | cut -d',' -f7)
        
        # Validate that we have numeric values
        if [ -z "$PYTHON_OPS" ] || [ -z "$CPP_OPS" ] || [ "$PYTHON_OPS" = "0" ]; then
          echo "Error: Invalid benchmark data in $CSV_FILE"
          echo "PYTHON_OPS: $PYTHON_OPS, CPP_OPS: $CPP_OPS"
          exit 1
        fi
        
        SPEEDUP=$(echo "scale=2; $CPP_OPS / $PYTHON_OPS" | bc)
        
        # Extract latency metrics
        PYTHON_LATENCY=$(tail -n +2 "$CSV_FILE" | head -n 1 | cut -d',' -f8)
        CPP_LATENCY=$(tail -n +2 "$CSV_FILE" | tail -n 1 | cut -d',' -f8)
        
        # Validate latency data
        if [ -z "$PYTHON_LATENCY" ] || [ -z "$CPP_LATENCY" ]; then
          echo "Error: Invalid latency data in $CSV_FILE"
          echo "PYTHON_LATENCY: $PYTHON_LATENCY, CPP_LATENCY: $CPP_LATENCY"
          exit 1
        fi
        
        # Calculate p95 latency (approximate from std dev)
        # Using 1.96 * std_dev approximation for 95th percentile
        PYTHON_P95=$(echo "scale=2; $PYTHON_LATENCY * 1.96" | bc)
        CPP_P95=$(echo "scale=2; $CPP_LATENCY * 1.96" | bc)
        BEST_P95=$(echo "scale=2; if ($PYTHON_P95 < $CPP_P95) $PYTHON_P95 else $CPP_P95" | bc)
        
        # Format throughput for display
        if (( $(echo "$PYTHON_OPS >= 1000000" | bc -l) )); then
          PYTHON_THROUGHPUT="${PYTHON_OPS%.*}M events/sec"
        elif (( $(echo "$PYTHON_OPS >= 1000" | bc -l) )); then
          PYTHON_THROUGHPUT="${PYTHON_OPS%.*}K events/sec"
        else
          PYTHON_THROUGHPUT="${PYTHON_OPS%.*} events/sec"
        fi
        
        if (( $(echo "$CPP_OPS >= 1000000" | bc -l) )); then
          CPP_THROUGHPUT="${CPP_OPS%.*}M events/sec"
        elif (( $(echo "$CPP_OPS >= 1000" | bc -l) )); then
          CPP_THROUGHPUT="${CPP_OPS%.*}K events/sec"
        else
          CPP_THROUGHPUT="${CPP_OPS%.*} events/sec"
        fi
        
        # Format latency
        if (( $(echo "$BEST_P95 < 1" | bc -l) )); then
          LATENCY_DISPLAY="$(echo "scale=0; $BEST_P95 * 1000" | bc) ns"
        else
          LATENCY_DISPLAY="$(echo "scale=0; $BEST_P95" | bc) Œºs"
        fi
        
        echo "speedup=$SPEEDUP" >> $GITHUB_OUTPUT
        echo "python_ops=$PYTHON_OPS" >> $GITHUB_OUTPUT
        echo "cpp_ops=$CPP_OPS" >> $GITHUB_OUTPUT
        echo "python_throughput=$PYTHON_THROUGHPUT" >> $GITHUB_OUTPUT
        echo "cpp_throughput=$CPP_THROUGHPUT" >> $GITHUB_OUTPUT
        echo "latency_p95=$LATENCY_DISPLAY" >> $GITHUB_OUTPUT
        
        # Print banner to CI logs
        echo ""
        echo "‚ö° Flashback C++ Engine Benchmark ‚ö°"
        echo "-----------------------------------"
        echo "Python engine throughput:   $PYTHON_THROUGHPUT"
        echo "C++ engine throughput:     $CPP_THROUGHPUT"
        echo "Speedup:                   ${SPEEDUP}√ó faster"
        echo "Latency p95:               $LATENCY_DISPLAY"
        echo ""
        
        # Create enhanced benchmark results JSON
        cat > bench_results.json << EOF
        {
          "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
          "python_ops_per_sec": $PYTHON_OPS,
          "cpp_ops_per_sec": $CPP_OPS,
          "speedup": $SPEEDUP,
          "python_throughput": "$PYTHON_THROUGHPUT",
          "cpp_throughput": "$CPP_THROUGHPUT",
          "latency_p95": "$LATENCY_DISPLAY",
          "python_latency_us": $PYTHON_LATENCY,
          "cpp_latency_us": $CPP_LATENCY,
          "environment": "GitHub Actions",
          "os": "ubuntu-latest",
          "python_version": "3.11"
        }
        EOF
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: |
          runs/*/benchmarks/
          ci_benchmark_results/
          bench_results.json
        retention-days: 30
    
    - name: Comment PR with benchmark results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          
          // Read benchmark results JSON
          let benchmarkData = {};
          if (fs.existsSync('bench_results.json')) {
            benchmarkData = JSON.parse(fs.readFileSync('bench_results.json', 'utf8'));
          }
          
          // Generate comment
          let comment = '## üöÄ Performance Benchmark Results\n\n';
          comment += `**Timestamp:** ${benchmarkData.timestamp || 'N/A'}\n`;
          comment += `**Environment:** ${benchmarkData.environment || 'GitHub Actions'}\n`;
          comment += `**Python Version:** ${benchmarkData.python_version || '3.11'}\n\n`;
          
          if (benchmarkData.speedup) {
            comment += '### ‚ö° Performance Summary\n\n';
            comment += '```\n';
            comment += '‚ö° Flashback C++ Engine Benchmark ‚ö°\n';
            comment += '-----------------------------------\n';
            comment += `Python engine throughput:   ${benchmarkData.python_throughput || 'N/A'}\n`;
            comment += `C++ engine throughput:     ${benchmarkData.cpp_throughput || 'N/A'}\n`;
            comment += `Speedup:                   ${parseFloat(benchmarkData.speedup).toFixed(1)}√ó faster\n`;
            comment += `Latency p95:               ${benchmarkData.latency_p95 || 'N/A'}\n`;
            comment += '```\n\n';
            
            // Add performance indicator
            const speedup = parseFloat(benchmarkData.speedup);
            if (speedup >= 8) {
              comment += '‚úÖ **Excellent performance!** C++ extension provides significant speedup.\n\n';
            } else if (speedup >= 5) {
              comment += '‚ö†Ô∏è **Good performance** - C++ extension provides moderate speedup.\n\n';
            } else {
              comment += '‚ùå **Performance issue** - C++ extension speedup is below expected levels.\n\n';
            }
          }
          
          comment += '### üîß Build Status\n\n';
          comment += '- ‚úÖ C++ extension built successfully\n';
          comment += '- ‚úÖ Bit-for-bit reproducibility test passed\n';
          comment += '- ‚úÖ Performance benchmarks completed\n\n';
          
          comment += '### üìÅ Artifacts\n\n';
          comment += 'Detailed benchmark results, plots, and performance data are available in the workflow artifacts.\n\n';
          
          comment += '### üìä C++ Extension Info\n\n';
          comment += 'The C++ matching engine is built using pybind11 and provides significant performance improvements for high-frequency trading simulations.';
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
